# [AI GENERATED] LLM: GitHub Copilot, Mode: Chat, Date: 2025-09-24
# Nginx configuration for load balancing
events {
    worker_connections 1024;
}

http {
    upstream school_backend {
        server school-service:8080;
        # Add more instances for load balancing
        # server school-service-2:8080;
        # server school-service-3:8080;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://school_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Health check bypass
            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;
        }

        location /health {
            proxy_pass http://school_backend/health;
            access_log off;
        }
    }
}